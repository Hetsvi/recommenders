{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique bigrams are 521502\n",
    "    The top bigrams are\n",
    "    [(7927, ('of', 'the')),\n",
    "     (5850, ('this', 'book')),\n",
    "     (5627, ('in', 'the')),\n",
    "     (3189, ('and', 'the')),\n",
    "     (3183, ('is', 'a'))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "data = []\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "data = df.iloc[:10000]\n",
    "data_review = data['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigram[words[j], words[j+1]] +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(bigram[w], w) for w in bigram]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7927, ('of', 'the')),\n",
       " (5850, ('this', 'book')),\n",
       " (5627, ('in', 'the')),\n",
       " (3189, ('and', 'the')),\n",
       " (3183, ('is', 'a'))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521502"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    wo = r.split()\n",
    "    for j in range(0, len(wo)-1): \n",
    "        w = wo[j], wo[j+1]\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data_review]\n",
    "y = [d for d in data['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0178804824879226\n"
     ]
    }
   ],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y, predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(73431, 'the'), (44301, 'and'), (39577, 'a'), (36821, 'to'), (36581, 'i'), (32552, 'of'), (21889, 'is'), (21468, 'in'), (20110, 'it'), (19353, 'this')]\n"
     ]
    }
   ],
   "source": [
    "uniwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for wuni in r.split():\n",
    "        uniwordCount[wuni] += 1\n",
    "unicounts = [(uniwordCount[wc], wc) for wc in uniwordCount]\n",
    "\n",
    "bigramc = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigramc[words[j] + ' '+ words[j+1]] +=1\n",
    "        \n",
    "counts = [(bigramc[w], w) for w in bigramc]    \n",
    "#print(counts[0])\n",
    "uni_bi = unicounts + counts\n",
    "uni_bi.sort()\n",
    "uni_bi.reverse()  \n",
    "#print(uni_bi[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_biwords = [x[1] for x in uni_bi[:1000]]\n",
    "\n",
    "### Sentiment analysis\n",
    "\n",
    "wordIdub = dict(zip(uni_biwords, range(len(uni_biwords))))\n",
    "wordSetub = set(uni_biwords)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(uni_biwords)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    wo = r.split()\n",
    "    for j, i in zip(range(0, len(wo)-1), wo): \n",
    "        w = wo[j] + ' '+ wo[j+1]\n",
    "        if w in uni_biwords:\n",
    "            feat[wordIdub[w]] += 1\n",
    "        if i in uni_biwords:\n",
    "            feat[wordIdub[i]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data_review]\n",
    "y = [d for d in data['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704424465275538\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "mse = sklearn.metrics.mean_squared_error(y, predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "data = df.iloc[:10000]\n",
    "data_review = data['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories 1.1018235165023234\n",
      "magician 2.4685210829577446\n",
      "psychic 5.075204004202088\n",
      "writing 0.9901243662878397\n",
      "wonder 1.09151498112135\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def tf(t, d):\n",
    "  #  word = []\n",
    "   ## for i in d.split():\n",
    "    #    words = []\n",
    "     #   word .append(i)\n",
    "    #print(word)\n",
    "    #wordCount = len(d.split())\n",
    "    count = 0\n",
    "    d = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for i in d.split():\n",
    "        if t == i:\n",
    "            #print(t)\n",
    "            count += 1\n",
    "    return float(count)\n",
    "\n",
    "def idf(t, file):\n",
    "    df = 0\n",
    "    #count = 0\n",
    "    count = len(file)\n",
    "    for i in file:\n",
    "        i = ''.join([c for c in i.lower() if not c in punctuation])\n",
    "        #print(t)\n",
    "        if t in i:\n",
    "            #count+= 1\n",
    "            #print(count)\n",
    "            df +=1 \n",
    "    return math.log((float(count)/float((df))), 10)\n",
    "    \n",
    "for i in ['stories', 'magician', 'psychic', 'writing', 'wonder']:\n",
    "    print(i , tf(i, data_review[0])*idf(i, data_review))\n",
    "\n",
    "#print(data_review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "data = df.iloc[:10000]\n",
    "data_review = data['review_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[569] in data_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwords = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, data_review)\n",
    "    #print(j)\n",
    "    idfwords.append(j)\n",
    "    #print(idfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idfwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwords):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data_review]\n",
    "y = [d for d in data['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(idfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in X[0]:\n",
    "    #print(i > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672305813829284\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "mse = sklearn.metrics.mean_squared_error(y, predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosinsim (vector, v):\n",
    "    magnitude = math.sqrt(sum(n**2 for n in vector))\n",
    "    mag = math.sqrt(sum(n**2 for n in v))\n",
    "    dot = sum(n*m for n, m in zip(vector, v))\n",
    "    m = magnitude*mag\n",
    "    answer = dot/m\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosin = 0\n",
    "index = 0\n",
    "#for i, j in zip(X, range(0, len(X))):\n",
    "for i in range(1, len(X)):\n",
    "    answers = cosinsim(X[0], X[i])\n",
    "    #$print(answers)\n",
    "    if answers > max_cosin:\n",
    "        max_cosin = answers\n",
    "        index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6921"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33740223573513983"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_review[9985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This review is going to be very personal. I will probably not talk about the writing, the plot or the characters the way that I normally would. Dear Martin is about 17-year-old Justyce McAllistera a highly successful black student who attends a primarily all-white private school. One day, he is helping a drunk friend and arrested. In response, he starts writing letters to Dr, Martin Luther King Jr. as a way to cope with his newly sharpened awareness of the world around him \\n The world needed this book right now. This is a book that every school needs. I am going to be buying copies for friends and family. I am a teacher. I can see how this book would be an excellent way to help students start having these difficult conversations. Because until we teach young people how to recognize and talk about racism, sexism, homophobia, and xenophobia and whatever else needs to get talked about nothing will change. They will unconsciously internalize the system\\'s biases. They won\\'t see the things that need to change. And that the things that need to change start with themselves. \\n I enjoyed the writing. There are quite a few conversations that are almost written like a script. Unusual but not distracting and I think that the convention highlighted the importance of what people were saying. I was fully investing the characters. So invested that if I don\\'t get regular updates about Justyce and assurances that he is thriving and well on his way to making the impact on the world that he deserves I am going to be so mad. Aside from Justyce, the standouts for me were Manny, SJ, Jared, and Doc. \\n One thing that seems to keep coming up is this sense of estrangement from self. Everyone in this novel (and most likely life) has this idea of who they are that doesn\\'t quite fit with the reality of who they are. There are these ideas and visions that other people have about them that they don\\'t know how to reconcile themselves with. Justyce struggles to reconcile the two sides of his life, Jared doesn\\'t recognize his internalized racism, and Manny overlooks \\n Justyce starts to talk about \"the Black Man\\'s Curse\" which I hadn\\'t heard about before. As I understand it, the BMC is the phenomenon that however well a black man does, however successful he may be they are never able to get to a point where they don\\'t have to worry about racism. Or about their race affecting their life. That someone is always waiting to slap you down, tread on your work, and assume that you don\\'t deserve your success because you are a black man. Just the short term second-hand frustration of reading about it was overwhelming. I cannot imagine what it is like to have to live with and deal with it for your entire life. How strong do you have to be to push through all that is holding you back? And what does it say about our society that we expect that? \\n So read this book. It is well written, it is important, and it is going to stay with you a long time after you finish the final page.'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_review[6921]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_review[6922]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for d in readGz(\"train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "data = df.iloc[:30000]\n",
    "data_reviewq = data['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "#random.shuffle(data_reviewq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_reviewq[:10000]\n",
    "validation = data_reviewq[10000:20000]\n",
    "test = data_reviewq[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)\n",
    "len(validation)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-47a0fc07718f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpunctuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_review\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-47a0fc07718f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpunctuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_review\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunctuation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "#bigram without pun\n",
    "bigram = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigram[words[j], words[j+1]] +=1\n",
    "counts = [(bigram[w], w) for w in bigram]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "#unigram without pun\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "#bigram with pun\n",
    "bigramwp = defaultdict(int)\n",
    "punctuation = list(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower()])\n",
    "    words =  [t.strip() for t in re.findall(r'\\b.*?\\S.*?(?:\\b|$)', r)]\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigramwp[words[j], words[j+1]] +=1\n",
    "countswp = [(bigramwp[w], w) for w in bigramwp]\n",
    "countswp.sort()\n",
    "countswp.reverse()\n",
    "\n",
    "#unigram with pun\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for w in [t.strip() for t in re.findall(r'\\b.*?\\S.*?(?:\\b|$)', r)]:\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "#re.findall(r\"[\\w']+|['!','\"',\"#\",'$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','|','}','~']\", \"Hello, I'm a string!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'world', '!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import re\n",
    ">>> sentence = 'Hello, world!!'\n",
    ">>> tokens = [t.strip() for t in re.findall(r'\\b.*?\\S.*?(?:\\b|$)', sentence)]\n",
    "['Hello', ',', 'world', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentence = 'Hello, world!!'\n",
    "tokens = [t.strip() for t in re.findall(r'\\b.*?\\S.*?(?:\\b|$)', sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '!!']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'world', '!', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sentence = 'Hello, world!!'\n",
    "tokens = [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", sentence)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split it into sets\n",
    "# words with punc bi\n",
    "# wors no punc bi\n",
    "# words with punc uni\n",
    "# words no punc uni\n",
    "\\# tfidf\n",
    "# bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Bigrams with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower()])\n",
    "    words = [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", r)]\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigram[words[j], words[j+1]] +=1\n",
    "        \n",
    "counts = [(bigram[w], w) for w in bigram]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum.lower()])\n",
    "    wo = [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", r)]\n",
    "    for j in range(0, len(wo)-1): \n",
    "        w = wo[j], wo[j+1]\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "X_vali = [feature(d) for d in validation]\n",
    "X_test = [feature(d) for d in test]\n",
    "y = [d for d in data['rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_bibagwp = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_bibagwp.append([mse,c])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.7633384790508368, 0.01],\n",
       " [1.7630522819206949, 0.1],\n",
       " [1.7602603926428755, 1],\n",
       " [1.7367797543001453, 10],\n",
       " [1.6344206961136214, 100]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_bibagwp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model bigram less bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigram[words[j], words[j+1]] +=1\n",
    "counts = [(bigram[w], w) for w in bigram]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    wo = r.split()\n",
    "    for j in range(0, len(wo)-1): \n",
    "        w = wo[j], wo[j+1]\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "X_vali = [feature(d) for d in validation]\n",
    "X_test = [feature(d) for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_bibag = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_bibag.append([mse,c, 'bibag'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.7535714973555219, 0.01, 'bibag'],\n",
       " [1.7532701639541546, 0.1, 'bibag'],\n",
       " [1.7503232446051902, 1, 'bibag'],\n",
       " [1.7253947206708733, 10, 'bibag'],\n",
       " [1.6179981892725532, 100, 'bibag']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_bibag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model unigram with bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for wuni in [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", r)]:\n",
    "        uniwordCount[wuni] += 1\n",
    "unicounts = [(uniwordCount[wc], wc) for wc in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "words = [x[1] for x in unicounts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    for w in [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", r)]:\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "X_vali = [feature(d) for d in validation]\n",
    "X_test = [feature(d) for d in test]\n",
    "y_train = [d for d in data['rating'][:10000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_ubagwp = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_ubagwp.append([mse,c, 'ubagwp'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model unigram less bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for wuni in r.split():\n",
    "        uniwordCount[wuni] += 1\n",
    "unicounts = [(uniwordCount[wc], wc) for wc in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "words = [x[1] for x in unicounts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for wuni in r.split():\n",
    "        if wuni in words:\n",
    "            feat[wordId[wuni]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "X_vali = [feature(d) for d in validation]\n",
    "X_test = [feature(d) for d in test]\n",
    "y_train = [d for d in data['rating'][:10000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_unibag = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_unibag.append([mse,c, 'unibag'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst = []\n",
    "#for j in X:\n",
    " #   count = 0\n",
    "  #  for i in j:\n",
    "   #     if int(i) != 0:\n",
    "    #        count = count +1\n",
    "    #lst.append(count)\n",
    "#print(count)\n",
    "#print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model bigrams with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idfp(t, file):\n",
    "    df = 0\n",
    "    #count = 0\n",
    "    count = len(file)\n",
    "    for i in file:\n",
    "        i = ''.join([c for c in i.lower()])\n",
    "        #print(t)\n",
    "        if t in i:\n",
    "            #count+= 1\n",
    "            #print(count)\n",
    "            df +=1 \n",
    "    return math.log((float(count)/float((df))), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idfp(t, file):\n",
    "    df = 0\n",
    "    #count = 0\n",
    "    count = len(file)\n",
    "    for i in file:\n",
    "        i = ''.join([c for c in i.lower()])\n",
    "        #print(t)\n",
    "        if t in i:\n",
    "            #count+= 1\n",
    "            #print(count)\n",
    "            df +=1 \n",
    "        if df == 0:\n",
    "            df = -1\n",
    "    return math.log((float(count)/float((df))), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idfp(t, file):\n",
    "    df = 0\n",
    "    #count = 0\n",
    "    count = len(file)\n",
    "    for i in file:\n",
    "        i = ''.join([c for c in i.lower()])\n",
    "        #print(t)\n",
    "        if t in i:\n",
    "            #count+= 1\n",
    "            #print(count)\n",
    "            df +=1 \n",
    "        if df == 0:\n",
    "            df = 1\n",
    "    return math.log((float(count)/float((df))), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idfp(t, file):\n",
    "    df = 0\n",
    "    #count = 0\n",
    "    count = len(file)\n",
    "    for i in file:\n",
    "        i = ''.join([c for c in i.lower()])\n",
    "        #print(t)\n",
    "        if t in i:\n",
    "            #count+= 1\n",
    "            #print(count)\n",
    "            df +=1 \n",
    "    if df == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return math.log((float(count)/float((df))), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower()])\n",
    "    words = [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", r)]\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigram[words[j] + ' '+ words[j+1]] +=1\n",
    "        \n",
    "counts = [(bigram[w], w) for w in bigram]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[0] in 'happy. i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = 'Happy!'\n",
    "#'!' in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[44] in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in train:\n",
    " #   print(words[43] in train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    i = ''.join([c for c in i.lower()])\n",
    "    if words[42] in i == True:\n",
    "        print(words[43] in train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    i = ''.join([c for c in i.lower()])\n",
    "    if words[40] in i == True:\n",
    "        print(words[42] in train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    if words[42] in train == True:\n",
    "        print(words[43] in train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwords = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idfp(i, train)\n",
    "    #print(j)\n",
    "    idfwords.append(j)\n",
    "    #print(idfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwords):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordsvali = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idfp(i, validation)\n",
    "    #print(j)\n",
    "    idfwordsvali.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurevali(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordsvali):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_vali = [featurevali(d) for d in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordstest = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idfp(i, test)\n",
    "    #print(j)\n",
    "    idfwordstest.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuretest(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordstest):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_test = [featuretest(d) for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwords):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "X_vali = [feature(d) for d in validation]\n",
    "X_test = [feature(d) for d in test]\n",
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_bitfwp = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_test)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_bitfwp.append([mse,c , 'bitfwp'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Bigrams less tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    words = r.split()\n",
    "    for j in range(0, len(words)-1):\n",
    "        bigram[words[j] + ' '+ words[j+1]] +=1\n",
    "        \n",
    "counts = [(bigram[w], w) for w in bigram]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwords = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, train)\n",
    "    #print(j)\n",
    "    idfwords.append(j)\n",
    "    #print(idfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentiment analysis\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwords):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordsvali = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, validation)\n",
    "    #print(j)\n",
    "    idfwordsvali.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurevali(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordsvali):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_vali = [featurevali(d) for d in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordstest = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, test)\n",
    "    #print(j)\n",
    "    idfwordstest.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuretest(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordstest):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_test = [featuretest(d) for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_bitf = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_bitf.append([mse,c , 'bitf'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model unigram with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "uniwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_reviewq:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for wuni in [t.strip() for t in re.findall(r\"[\\w']+|[.,!?;]\", r)]:\n",
    "        uniwordCount[wuni] += 1\n",
    "unicounts = [(uniwordCount[wc], wc) for wc in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "words = [x[1] for x in unicounts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwords = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, train)\n",
    "    #print(j)\n",
    "    idfwords.append(j)\n",
    "    #print(idfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwords):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordsvali = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, validation)\n",
    "    #print(j)\n",
    "    idfwordsvali.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurevali(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordsvali):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_vali = [featurevali(d) for d in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordstest = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, test)\n",
    "    #print(j)\n",
    "    idfwordstest.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuretest(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordstest):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_test = [featuretest(d) for d in test]\n",
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8435331199038523 0.01\n",
      "1.8418910708574914 0.1\n",
      "1.8379322157712121 1\n",
      "1.820328427984602 10\n",
      "1.7452302239633442 100\n"
     ]
    }
   ],
   "source": [
    "mse_utfwp = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_utfwp.append([mse,c, 'utfwp'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model unigram less tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data_review:\n",
    "    r = ''.join([c for c in d.lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwords = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, train)\n",
    "    #print(j)\n",
    "    idfwords.append(j)\n",
    "    #print(idfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwords):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in train]\n",
    "y_train = [d for d in data['rating'][:10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordsvali = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, validation)\n",
    "    #print(j)\n",
    "    idfwordsvali.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurevali(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordsvali):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_vali = [featurevali(d) for d in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfwordstest = []\n",
    "for i in words:\n",
    "    #print(i)\n",
    "    j = idf(i, test)\n",
    "    #print(j)\n",
    "    idfwordstest.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuretest(datum):\n",
    "    feat = [0]*len(words)\n",
    "    for i, j in zip(words, idfwordstest):\n",
    "        #print(tf(i, datum))\n",
    "        feat.append(tf(i, datum)* j)\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "X_test = [featuretest(d) for d in test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453519100143996 0.01\n",
      "1.345351911439946 0.1\n",
      "1.3453520539686856 1\n",
      "1.3453662809917355 10\n",
      "1.3467635116165084 100\n"
     ]
    }
   ],
   "source": [
    "mse_utf = []\n",
    "# Regularized regression\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    clf = linear_model.Ridge(c, fit_intercept=False) # MSE + 1.0 l2\n",
    "    clf.fit(X, y_train)\n",
    "    theta = clf.coef_\n",
    "    predictions = clf.predict(X_vali)\n",
    "    mse = sklearn.metrics.mean_squared_error(y_train, predictions)\n",
    "    mse_utf.append([mse,c, 'utf'])\n",
    "    print(mse, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+ mse_unibag + mse_bitfwp + mse_bitf mse_utfwp + mse_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    " #mse_bibagwp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_bibag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_ubagwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_unibag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_bitfwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_bitf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    " #mse_utfwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse_utf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
